{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport numpy as np\nimport pandas as pd\nfrom tensorflow.keras.models import load_model\nimport numpy as np\nimport keras.backend as K\nimport cv2\nimport lime ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-08T15:53:50.522037Z","iopub.execute_input":"2023-11-08T15:53:50.522747Z","iopub.status.idle":"2023-11-08T15:54:00.663408Z","shell.execute_reply.started":"2023-11-08T15:53:50.522715Z","shell.execute_reply":"2023-11-08T15:54:00.662367Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport time","metadata":{"execution":{"iopub.status.busy":"2023-11-08T15:54:00.665416Z","iopub.execute_input":"2023-11-08T15:54:00.666387Z","iopub.status.idle":"2023-11-08T15:54:00.670343Z","shell.execute_reply.started":"2023-11-08T15:54:00.666355Z","shell.execute_reply":"2023-11-08T15:54:00.669380Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\n\nimport os\nimport keras\nfrom keras.applications import inception_v3 as inc_net\nfrom keras.preprocessing import image\nfrom keras.applications.imagenet_utils import decode_predictions\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport numpy as np\nprint('Notebook run using keras:', keras.__version__)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-08T15:54:00.671500Z","iopub.execute_input":"2023-11-08T15:54:00.671809Z","iopub.status.idle":"2023-11-08T15:54:01.065850Z","shell.execute_reply.started":"2023-11-08T15:54:00.671781Z","shell.execute_reply":"2023-11-08T15:54:01.064990Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Notebook run using keras: 2.12.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# Charger le modèle\nmodel = load_model(\"/kaggle/input/bootstrap-data/ModelSjogrenn(2).h5\")\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-08T15:54:01.067985Z","iopub.execute_input":"2023-11-08T15:54:01.068697Z","iopub.status.idle":"2023-11-08T15:54:01.803401Z","shell.execute_reply.started":"2023-11-08T15:54:01.068667Z","shell.execute_reply":"2023-11-08T15:54:01.802513Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-08T15:54:01.805216Z","iopub.execute_input":"2023-11-08T15:54:01.806047Z","iopub.status.idle":"2023-11-08T15:54:01.851102Z","shell.execute_reply.started":"2023-11-08T15:54:01.806006Z","shell.execute_reply":"2023-11-08T15:54:01.850128Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 502, 502, 32)      3904      \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 251, 251, 32)     0         \n )                                                               \n                                                                 \n conv2d_1 (Conv2D)           (None, 245, 245, 32)      50208     \n                                                                 \n max_pooling2d_1 (MaxPooling  (None, 122, 122, 32)     0         \n 2D)                                                             \n                                                                 \n conv2d_2 (Conv2D)           (None, 116, 116, 32)      50208     \n                                                                 \n max_pooling2d_2 (MaxPooling  (None, 58, 58, 32)       0         \n 2D)                                                             \n                                                                 \n conv2d_3 (Conv2D)           (None, 52, 52, 16)        25104     \n                                                                 \n max_pooling2d_3 (MaxPooling  (None, 26, 26, 16)       0         \n 2D)                                                             \n                                                                 \n conv2d_4 (Conv2D)           (None, 20, 20, 16)        12560     \n                                                                 \n max_pooling2d_4 (MaxPooling  (None, 10, 10, 16)       0         \n 2D)                                                             \n                                                                 \n flatten (Flatten)           (None, 1600)              0         \n                                                                 \n dense (Dense)               (None, 128)               204928    \n                                                                 \n dense_1 (Dense)             (None, 64)                8256      \n                                                                 \n dense_2 (Dense)             (None, 16)                1040      \n                                                                 \n dense_3 (Dense)             (None, 1)                 17        \n                                                                 \n=================================================================\nTotal params: 356,225\nTrainable params: 356,225\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2023-11-08T15:54:01.852313Z","iopub.execute_input":"2023-11-08T15:54:01.852728Z","iopub.status.idle":"2023-11-08T15:54:01.861040Z","shell.execute_reply.started":"2023-11-08T15:54:01.852691Z","shell.execute_reply":"2023-11-08T15:54:01.860194Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<keras.engine.sequential.Sequential at 0x79fd96b85960>"},"metadata":{}}]},{"cell_type":"code","source":"\n\nx=np.load(\"/kaggle/input/bootstrap-data/x_test(2).npy\")\ny=np.load(\"/kaggle/input/bootstrap-data/y_test(2).npy\")\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-08T15:54:01.862387Z","iopub.execute_input":"2023-11-08T15:54:01.862814Z","iopub.status.idle":"2023-11-08T15:54:13.151297Z","shell.execute_reply.started":"2023-11-08T15:54:01.862759Z","shell.execute_reply":"2023-11-08T15:54:13.150094Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"from PIL import Image\n\nimage1=Image.open(\"/kaggle/input/sjdata/DATA_(512,512)/sj_data/019.jpg\")\nimage2=Image.open(\"/kaggle/input/sjdata/DATA_(512,512)/sj_data/013.jpg\")\nimage3=Image.open(\"/kaggle/input/sjdata/DATA_(512,512)/sj_data/020.jpg\")\n\n\n\n\nimage4=Image.open(\"/kaggle/input/sjdata/DATA_(512,512)/nsj_data/004.jpg\")\nimage5=Image.open(\"/kaggle/input/sjdata/DATA_(512,512)/nsj_data/005.jpg\")\nimage6=Image.open(\"/kaggle/input/sjdata/DATA_(512,512)/nsj_data/224.jpg\")\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-05T13:08:16.729305Z","iopub.execute_input":"2023-11-05T13:08:16.730537Z","iopub.status.idle":"2023-11-05T13:08:16.751790Z","shell.execute_reply.started":"2023-11-05T13:08:16.730482Z","shell.execute_reply":"2023-11-05T13:08:16.750279Z"}}},{"cell_type":"code","source":"from PIL import Image\nchemin_image = \"/kaggle/input/sjdata/DATA_(512,512)/sj_data/019.jpg\"\nimage=Image.open(chemin_image)","metadata":{"execution":{"iopub.status.busy":"2023-11-08T15:54:13.155238Z","iopub.execute_input":"2023-11-08T15:54:13.156015Z","iopub.status.idle":"2023-11-08T15:54:13.188275Z","shell.execute_reply.started":"2023-11-08T15:54:13.155974Z","shell.execute_reply":"2023-11-08T15:54:13.187220Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from skimage.color import rgb2gray\nimg=np.array(image)","metadata":{"execution":{"iopub.status.busy":"2023-11-08T15:54:13.190357Z","iopub.execute_input":"2023-11-08T15:54:13.191170Z","iopub.status.idle":"2023-11-08T15:54:13.203484Z","shell.execute_reply.started":"2023-11-08T15:54:13.191121Z","shell.execute_reply":"2023-11-08T15:54:13.202223Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Convert to RGB mode\nimg_resized_rgb1 = image1.convert(\"RGB\")\nimg_resized_rgb2 = image2.convert(\"RGB\")\nimg_resized_rgb3 = image3.convert(\"RGB\")\nimg_resized_rgb4 = image4.convert(\"RGB\")\nimg_resized_rgb5 = image5.convert(\"RGB\")\n\nimg_resized_rgb6 = image6.convert(\"RGB\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-08T15:54:13.205297Z","iopub.execute_input":"2023-11-08T15:54:13.205742Z","iopub.status.idle":"2023-11-08T15:54:14.033098Z","shell.execute_reply.started":"2023-11-08T15:54:13.205703Z","shell.execute_reply":"2023-11-08T15:54:14.031400Z"},"trusted":true},"execution_count":10,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Convert to RGB mode\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m img_resized_rgb1 \u001b[38;5;241m=\u001b[39m \u001b[43mimage1\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m img_resized_rgb2 \u001b[38;5;241m=\u001b[39m image2\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m img_resized_rgb3 \u001b[38;5;241m=\u001b[39m image3\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'image1' is not defined"],"ename":"NameError","evalue":"name 'image1' is not defined","output_type":"error"}]},{"cell_type":"code","source":"img1=np.array(img_resized_rgb1)\nimg2=np.array(img_resized_rgb2)\nimg3=np.array(img_resized_rgb3)\nimg4=np.array(img_resized_rgb4)\nimg5=np.array(img_resized_rgb5)\nimg6=np.array(img_resized_rgb6)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-08T15:54:14.034045Z","iopub.status.idle":"2023-11-08T15:54:14.034492Z","shell.execute_reply.started":"2023-11-08T15:54:14.034292Z","shell.execute_reply":"2023-11-08T15:54:14.034311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gray_image = np.expand_dims(img, axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-11-08T15:54:14.035731Z","iopub.status.idle":"2023-11-08T15:54:14.037138Z","shell.execute_reply.started":"2023-11-08T15:54:14.036879Z","shell.execute_reply":"2023-11-08T15:54:14.036901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gray_image.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-08T15:54:14.038226Z","iopub.status.idle":"2023-11-08T15:54:14.038997Z","shell.execute_reply.started":"2023-11-08T15:54:14.038688Z","shell.execute_reply":"2023-11-08T15:54:14.038715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shap","metadata":{"execution":{"iopub.status.busy":"2023-11-08T15:54:14.040814Z","iopub.status.idle":"2023-11-08T15:54:14.041388Z","shell.execute_reply.started":"2023-11-08T15:54:14.041115Z","shell.execute_reply":"2023-11-08T15:54:14.041140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def f(x):\n    tmp = x.copy()\n    y_pred = model.predict(tmp)\n    y_pred_classes = np.where(y_pred>0.5,1.,0)\n    return y_pred_classes","metadata":{"execution":{"iopub.status.busy":"2023-11-08T15:54:14.042700Z","iopub.status.idle":"2023-11-08T15:54:14.043941Z","shell.execute_reply.started":"2023-11-08T15:54:14.043662Z","shell.execute_reply":"2023-11-08T15:54:14.043688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define a masker that is used to mask out partitions of the input image.\nmasker_blur = shap.maskers.Image(\"blur(512,512)\", gray_image.shape)\nclass_names=[\"sjogren\",\"non_sjogren\"]\n# create an explainer with model and image masker\nexplainer_blur = shap.Explainer(f, masker_blur, output_names=class_names)\n\n# here we explain two images using 500 evaluations of the underlying model to estimate the SHAP values\nshap_values_fine = explainer_blur(\n    gray_image, max_evals=5000, batch_size=50, outputs=shap.Explanation.argsort.flip[:4]\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T13:08:07.110880Z","iopub.status.idle":"2023-11-05T13:08:07.111482Z","shell.execute_reply.started":"2023-11-05T13:08:07.111282Z","shell.execute_reply":"2023-11-05T13:08:07.111303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_array=x[2]","metadata":{"execution":{"iopub.status.busy":"2023-11-08T13:40:02.487568Z","iopub.execute_input":"2023-11-08T13:40:02.487972Z","iopub.status.idle":"2023-11-08T13:40:02.493291Z","shell.execute_reply.started":"2023-11-08T13:40:02.487941Z","shell.execute_reply":"2023-11-08T13:40:02.492147Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"img_array = np.expand_dims(img, axis=-1)\nimg_array = np.expand_dims(img, axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-11-08T15:54:17.373426Z","iopub.execute_input":"2023-11-08T15:54:17.373838Z","iopub.status.idle":"2023-11-08T15:54:17.379389Z","shell.execute_reply.started":"2023-11-08T15:54:17.373805Z","shell.execute_reply":"2023-11-08T15:54:17.378310Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"img_array.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-08T15:54:18.248230Z","iopub.execute_input":"2023-11-08T15:54:18.248619Z","iopub.status.idle":"2023-11-08T15:54:18.255258Z","shell.execute_reply.started":"2023-11-08T15:54:18.248589Z","shell.execute_reply":"2023-11-08T15:54:18.254159Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(1, 512, 512)"},"metadata":{}}]},{"cell_type":"code","source":"preds = model.predict(img_array)","metadata":{"execution":{"iopub.status.busy":"2023-11-08T15:55:41.072049Z","iopub.execute_input":"2023-11-08T15:55:41.072442Z","iopub.status.idle":"2023-11-08T15:55:41.648458Z","shell.execute_reply.started":"2023-11-08T15:55:41.072413Z","shell.execute_reply":"2023-11-08T15:55:41.647532Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 479ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\n\nwith open('predictions.json', 'w') as file:\n    json.dump({'probabilities': probabilites.tolist()}, file)","metadata":{"execution":{"iopub.status.busy":"2023-11-08T14:04:04.184641Z","iopub.execute_input":"2023-11-08T14:04:04.185085Z","iopub.status.idle":"2023-11-08T14:04:04.193023Z","shell.execute_reply.started":"2023-11-08T14:04:04.185052Z","shell.execute_reply":"2023-11-08T14:04:04.191747Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"array([1.], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"preds = model.predict(img_array)\n\n# Initialiser SHAP\nexplainer = shap.DeepExplainer(model, img_array)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-05T13:12:57.592376Z","iopub.execute_input":"2023-11-05T13:12:57.592989Z","iopub.status.idle":"2023-11-05T13:12:58.007177Z","shell.execute_reply.started":"2023-11-05T13:12:57.592937Z","shell.execute_reply":"2023-11-05T13:12:58.006086Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 165ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Calculer les valeurs SHAP\nshap_values = explainer.shap_values(img_array)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-05T13:24:17.970517Z","iopub.execute_input":"2023-11-05T13:24:17.971013Z","iopub.status.idle":"2023-11-05T13:24:20.130992Z","shell.execute_reply.started":"2023-11-05T13:24:17.970976Z","shell.execute_reply":"2023-11-05T13:24:20.129396Z"},"trusted":true},"execution_count":46,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Calculer les valeurs SHAP\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_array\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/shap/explainers/_deep/__init__.py:124\u001b[0m, in \u001b[0;36mDeep.shap_values\u001b[0;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshap_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, ranked_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, output_rank_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, check_additivity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     91\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Return approximate SHAP values for the model applied to the data given by X.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m        were chosen as \"top\".\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranked_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_rank_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_additivity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_additivity\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/shap/explainers/_deep/deep_tf.py:323\u001b[0m, in \u001b[0;36mTFDeep.shap_values\u001b[0;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;66;03m# assign the attributions to the right part of the output arrays\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X)):\n\u001b[0;32m--> 323\u001b[0m             \u001b[43mphis\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m (sample_phis[l][bg_data[l]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:] \u001b[38;5;241m*\u001b[39m (X[l][j] \u001b[38;5;241m-\u001b[39m bg_data[l]))\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    325\u001b[0m     output_phis\u001b[38;5;241m.\u001b[39mappend(phis[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_input \u001b[38;5;28;01melse\u001b[39;00m phis)\n\u001b[1;32m    327\u001b[0m \u001b[38;5;66;03m# check that the SHAP values sum up to the model output\u001b[39;00m\n","\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (512,512,512) into shape (512,512)"],"ename":"ValueError","evalue":"could not broadcast input array from shape (512,512,512) into shape (512,512)","output_type":"error"}]},{"cell_type":"code","source":"\n# Afficher le résumé du plot\nshap.image_plot(shap_values, -img_array)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# output with shap values\nshap.image_plot(shap_values_fine)\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install -U scipy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skimage.segmentation import quickshift,mark_boundaries\nfrom skimage.color import gray2rgb\nimport skimage.io","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xi1 = skimage.transform.resize(img1, (512,512)) # resizing image\nskimage.io.imshow(Xi1)# Show image \nXi1 = (Xi1 - 0.5)*2\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nXi2 = skimage.transform.resize(img2, (512,512)) # resizing image\nskimage.io.imshow(Xi2)# Show image \nXi2 = (Xi2 - 0.5)*2\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xi3 = skimage.transform.resize(img3, (512,512)) # resizing image\nskimage.io.imshow(Xi3)# Show image \nXi3 = (Xi3 - 0.5)*2\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xi4 = skimage.transform.resize(img4, (512,512)) # resizing image\nskimage.io.imshow(Xi4)# Show image \nXi4 = (Xi4 - 0.5)*2\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xi5 = skimage.transform.resize(img5, (512,512)) # resizing image\nskimage.io.imshow(Xi5)# Show image \nXi5 = (Xi5 - 0.5)*2\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nXi6 = skimage.transform.resize(img6, (512,512)) # resizing image\nskimage.io.imshow(Xi6)# Show image \nXi6 = (Xi6 - 0.5)*2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"superpixels1 = quickshift(Xi1, kernel_size=2,max_dist=200, ratio=0.2) #the higher the kernel size,max_dist, the fewer are the clusters","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"superpixels2 = quickshift(Xi2, kernel_size=2,max_dist=200, ratio=0.2) #the higher the kernel size,max_dist, the fewer are the clusters","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"superpixels3= quickshift(Xi3, kernel_size=2,max_dist=200, ratio=0.2) #the higher the kernel size,max_dist, the fewer are the clusters","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"superpixels4 = quickshift(Xi4, kernel_size=2,max_dist=200, ratio=0.2) #the higher the kernel size,max_dist, the fewer are the clusters","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"superpixels5 = quickshift(Xi5, kernel_size=2,max_dist=200, ratio=0.2) #the higher the kernel size,max_dist, the fewer are the clusters","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"superpixels6 = quickshift(Xi6, kernel_size=2,max_dist=200, ratio=0.2) #the higher the kernel size,max_dist, the fewer are the clusters","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Segments image using quickshift clustering\nnum_superpixels1 = np.unique(superpixels1).shape[0]\nprint(\"The number of super pixels generated\")\nnum_superpixels1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Segments image using quickshift clustering\nnum_superpixels2 = np.unique(superpixels2).shape[0]\nprint(\"The number of super pixels generated\")\nnum_superpixels2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Segments image using quickshift clustering\nnum_superpixels3 = np.unique(superpixels3).shape[0]\nprint(\"The number of super pixels generated\")\nnum_superpixels3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Segments image using quickshift clustering\nnum_superpixels4 = np.unique(superpixels4).shape[0]\nprint(\"The number of super pixels generated\")\nnum_superpixels4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Segments image using quickshift clustering\nnum_superpixels5 = np.unique(superpixels5).shape[0]\nprint(\"The number of super pixels generated\")\nnum_superpixels5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Segments image using quickshift clustering\nnum_superpixels6 = np.unique(superpixels6).shape[0]\nprint(\"The number of super pixels generated\")\nnum_superpixels6","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skimage.io.imshow(mark_boundaries(Xi1/2+0.5, superpixels1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skimage.io.imshow(mark_boundaries(Xi2/2+0.5, superpixels2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skimage.io.imshow(mark_boundaries(Xi3/2+0.5, superpixels3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skimage.io.imshow(mark_boundaries(Xi4/2+0.5, superpixels4))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skimage.io.imshow(mark_boundaries(Xi5/2+0.5, superpixels5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skimage.io.imshow(mark_boundaries(Xi6/2+0.5, superpixels6))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(120)\nnum_perturb = 100\n#150 perturbations\nperturbations1 = np.random.binomial(1, 0.5, size=(num_perturb, num_superpixels1))# The size corresponds to the (no. of perturbations x no. of superpixels) in the image.\nprint(\" Here, '1' represent ON(active) superpixel and '0' represents OFF.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(120)\nnum_perturb = 100\n#150 perturbations\nperturbations2= np.random.binomial(1, 0.5, size=(num_perturb, num_superpixels2))# The size corresponds to the (no. of perturbations x no. of superpixels) in the image.\nprint(\" Here, '1' represent ON(active) superpixel and '0' represents OFF.\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(120)\nnum_perturb = 100\n#150 perturbations\nperturbations3 = np.random.binomial(1, 0.5, size=(num_perturb, num_superpixels3))# The size corresponds to the (no. of perturbations x no. of superpixels) in the image.\nprint(\" Here, '1' represent ON(active) superpixel and '0' represents OFF.\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(120)\nnum_perturb = 100\n#150 perturbations\nperturbations4 = np.random.binomial(1, 0.5, size=(num_perturb, num_superpixels4))# The size corresponds to the (no. of perturbations x no. of superpixels) in the image.\nprint(\" Here, '1' represent ON(active) superpixel and '0' represents OFF.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(120)\nnum_perturb = 100\n#150 perturbations\nperturbations5 = np.random.binomial(1, 0.5, size=(num_perturb, num_superpixels5))# The size corresponds to the (no. of perturbations x no. of superpixels) in the image.\nprint(\" Here, '1' represent ON(active) superpixel and '0' represents OFF.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(120)\nnum_perturb = 100\n#150 perturbations\nperturbations6 = np.random.binomial(1, 0.5, size=(num_perturb, num_superpixels6))# The size corresponds to the (no. of perturbations x no. of superpixels) in the image.\nprint(\" Here, '1' represent ON(active) superpixel and '0' represents OFF.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nimport copy\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def perturb_image(img,perturbation,segments): #takes in the parameters : raw image, perturbation vector and superpixels generated\n  active_pixels = np.where(perturbation == 1)[0]\n  mask = np.zeros(segments.shape)\n  for active in active_pixels:\n      mask[segments == active] = 1 \n  perturbed_image = copy.deepcopy(img)\n  perturbed_image = perturbed_image*mask[:,:,np.newaxis]\n  return perturbed_image #returns the perturbed image\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"The perturbed image\")\nskimage.io.imshow(perturb_image(Xi1/2+0.5,perturbations1[0],superpixels1)) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skimage.color import rgb2gray","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im1 = np.array(image1)\nim2 = np.array(image2)\nim3 = np.array(image3)\nim4 = np.array(image4)\nim5 = np.array(image5)\nim6 = np.array(image6)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions1 = []\nfor pert in perturbations1:\n  perturbed_img = perturb_image(Xi1,pert,superpixels1)\n  # Assuming your image is stored in a variable called 'image'\n  gray_image = rgb2gray(perturbed_img)\n  gray_image = gray_image.astype(np.float32)\n  gray_image = np.expand_dims(im1, axis=0)\n  print(gray_image.shape)\n  pred = model.predict(gray_image)\n  predictions1.append(pred)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions2 = []\nfor pert in perturbations2:\n  perturbed_img = perturb_image(Xi2,pert,superpixels2)\n  # Assuming your image is stored in a variable called 'image'\n  gray_image = rgb2gray(perturbed_img)\n  gray_image = gray_image.astype(np.float32)\n  gray_image = np.expand_dims(im2, axis=0)\n  print(gray_image.shape)\n  pred = model.predict(gray_image)\n  predictions2.append(pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions3 = []\nfor pert in perturbations3:\n  perturbed_img = perturb_image(Xi3,pert,superpixels3)\n  # Assuming your image is stored in a variable called 'image'\n  gray_image = rgb2gray(perturbed_img)\n  gray_image = gray_image.astype(np.float32)\n  gray_image = np.expand_dims(im3, axis=0)\n  print(gray_image.shape)\n  pred = model.predict(gray_image)\n  predictions3.append(pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions4 = []\nfor pert in perturbations4:\n  perturbed_img = perturb_image(Xi4,pert,superpixels4)\n  # Assuming your image is stored in a variable called 'image'\n  gray_image = rgb2gray(perturbed_img)\n  gray_image = gray_image.astype(np.float32)\n  gray_image = np.expand_dims(im4, axis=0)\n  print(gray_image.shape)\n  pred = model.predict(gray_image)\n  predictions4.append(pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions5 = []\nfor pert in perturbations5:\n  perturbed_img = perturb_image(Xi5,pert,superpixels5)\n  # Assuming your image is stored in a variable called 'image'\n  gray_image = rgb2gray(perturbed_img)\n  gray_image = gray_image.astype(np.float32)\n  gray_image = np.expand_dims(im5, axis=0)\n  print(gray_image.shape)\n  pred = model.predict(gray_image)\n  predictions5.append(pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions6 = []\nfor pert in perturbations6:\n  perturbed_img = perturb_image(Xi6,pert,superpixels6)\n  # Assuming your image is stored in a variable called 'image'\n  gray_image = rgb2gray(perturbed_img)\n  gray_image = gray_image.astype(np.float32)\n  gray_image = np.expand_dims(im6, axis=0)\n  print(gray_image.shape)\n  pred = model.predict(gray_image)\n  predictions6.append(pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn.metrics","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original_image1 = np.ones(num_superpixels1)[np.newaxis,:] #Perturbation with all superpixels enabled \n#The distance between each randomly generated perturnation and the image being explained is computed using the cosine distance. \ndistances1 = sklearn.metrics.pairwise_distances(perturbations1,original_image1, metric='cosine').ravel()#ravel() function is used to create a contiguous flattened array.\n#distances","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original_image2 = np.ones(num_superpixels2)[np.newaxis,:] #Perturbation with all superpixels enabled \n#The distance between each randomly generated perturnation and the image being explained is computed using the cosine distance. \ndistances2 = sklearn.metrics.pairwise_distances(perturbations2,original_image2, metric='cosine').ravel()#ravel() function is used to create a contiguous flattened array.\n#distances","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original_image3 = np.ones(num_superpixels3)[np.newaxis,:] #Perturbation with all superpixels enabled \n#The distance between each randomly generated perturnation and the image being explained is computed using the cosine distance. \ndistances3= sklearn.metrics.pairwise_distances(perturbations3,original_image3, metric='cosine').ravel()#ravel() function is used to create a contiguous flattened array.\n#distances","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original_image4 = np.ones(num_superpixels4)[np.newaxis,:] #Perturbation with all superpixels enabled \n#The distance between each randomly generated perturnation and the image being explained is computed using the cosine distance. \ndistances4 = sklearn.metrics.pairwise_distances(perturbations4,original_image4, metric='cosine').ravel()#ravel() function is used to create a contiguous flattened array.\n#distances","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original_image5 = np.ones(num_superpixels5)[np.newaxis,:] #Perturbation with all superpixels enabled \n#The distance between each randomly generated perturnation and the image being explained is computed using the cosine distance. \ndistances5 = sklearn.metrics.pairwise_distances(perturbations5,original_image5, metric='cosine').ravel()#ravel() function is used to create a contiguous flattened array.\n#distances","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original_image6 = np.ones(num_superpixels6)[np.newaxis,:] #Perturbation with all superpixels enabled \n#The distance between each randomly generated perturnation and the image being explained is computed using the cosine distance. \ndistances6 = sklearn.metrics.pairwise_distances(perturbations6,original_image6, metric='cosine').ravel()#ravel() function is used to create a contiguous flattened array.\n#distances","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kernel_width = 0.25\nweights1 = np.sqrt(np.exp(-(distances1**2)/kernel_width**2)) #Kernel function\nweights1.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kernel_width = 0.25\nweights2 = np.sqrt(np.exp(-(distances2**2)/kernel_width**2)) #Kernel function\nweights2.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kernel_width = 0.25\nweights3 = np.sqrt(np.exp(-(distances3**2)/kernel_width**2)) #Kernel function\nweights3.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kernel_width = 0.25\nweights4 = np.sqrt(np.exp(-(distances4**2)/kernel_width**2)) #Kernel function\nweights4.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kernel_width = 0.25\nweights5 = np.sqrt(np.exp(-(distances5**2)/kernel_width**2)) #Kernel function\nweights5.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kernel_width = 0.25\nweights6 = np.sqrt(np.exp(-(distances6**2)/kernel_width**2)) #Kernel function\nweights6.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions1 = np.array(predictions1)\npredictions2 = np.array(predictions2)\npredictions3 = np.array(predictions3)\npredictions4 = np.array(predictions4)\npredictions5 = np.array(predictions5)\npredictions6 = np.array(predictions6)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions1.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top_pred_classes=(0,1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"simpler_model = LinearRegression()\nsimpler_model.fit(X=perturbations1, y=predictions1[:,:,top_pred_classes[0]], sample_weight=weights1) # the top predicted class is to be explained\ncoeff1 = simpler_model.coef_[0] \ncoeff1.shape # Each coefficient in the linear model corresponds to one superpixel in the segmented image.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"simpler_model = LinearRegression()\nsimpler_model.fit(X=perturbations2, y=predictions2[:,:,top_pred_classes[0]], sample_weight=weights2) # the top predicted class is to be explained\ncoeff2 = simpler_model.coef_[0] \ncoeff2.shape # Each coefficient in the linear model corresponds to one superpixel in the segmented image.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"simpler_model = LinearRegression()\nsimpler_model.fit(X=perturbations3, y=predictions3[:,:,top_pred_classes[0]], sample_weight=weights3) # the top predicted class is to be explained\ncoeff3 = simpler_model.coef_[0] \ncoeff3.shape # Each coefficient in the linear model corresponds to one superpixel in the segmented image.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"simpler_model = LinearRegression()\nsimpler_model.fit(X=perturbations4, y=predictions4[:,:,top_pred_classes[0]], sample_weight=weights4) # the top predicted class is to be explained\ncoeff4 = simpler_model.coef_[0] \ncoeff4.shape # Each coefficient in the linear model corresponds to one superpixel in the segmented image.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"simpler_model = LinearRegression()\nsimpler_model.fit(X=perturbations5, y=predictions5[:,:,top_pred_classes[0]], sample_weight=weights5) # the top predicted class is to be explained\ncoeff5 = simpler_model.coef_[0] \ncoeff5.shape # Each coefficient in the linear model corresponds to one superpixel in the segmented image.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"simpler_model = LinearRegression()\nsimpler_model.fit(X=perturbations6, y=predictions6[:,:,top_pred_classes[0]], sample_weight=weights6) # the top predicted class is to be explained\ncoeff6 = simpler_model.coef_[0] \ncoeff6.shape # Each coefficient in the linear model corresponds to one superpixel in the segmented image.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_top_features = 400\ntop_features1 = np.argsort(coeff1)[-num_top_features:] \n#Now we need to sort the coefficients to figure out which are the superpixels that have larger coefficients (magnitude) for the prediction of egyptian cat. \ntop_features1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_top_features = 400\ntop_features2 = np.argsort(coeff2)[-num_top_features:] \n#Now we need to sort the coefficients to figure out which are the superpixels that have larger coefficients (magnitude) for the prediction of egyptian cat. \ntop_features2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_top_features = 400\ntop_features3 = np.argsort(coeff3)[-num_top_features:] \n#Now we need to sort the coefficients to figure out which are the superpixels that have larger coefficients (magnitude) for the prediction of egyptian cat. \ntop_features3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_top_features = 400\ntop_features4 = np.argsort(coeff4)[-num_top_features:] \n#Now we need to sort the coefficients to figure out which are the superpixels that have larger coefficients (magnitude) for the prediction of egyptian cat. \ntop_features4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_top_features = 400\ntop_features5 = np.argsort(coeff5)[-num_top_features:] \n#Now we need to sort the coefficients to figure out which are the superpixels that have larger coefficients (magnitude) for the prediction of egyptian cat. \ntop_features5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_top_features = 400\ntop_features6 = np.argsort(coeff6)[-num_top_features:] \n#Now we need to sort the coefficients to figure out which are the superpixels that have larger coefficients (magnitude) for the prediction of egyptian cat. \ntop_features6","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask1 = np.zeros(num_superpixels1) #The less relevant pixels are black and only the top superpixels are activated.\nmask1[top_features1]= True \nskimage.io.imshow(perturb_image(Xi1/2+0.5,mask1,superpixels1) )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask2 = np.zeros(num_superpixels2) #The less relevant pixels are black and only the top superpixels are activated.\nmask2[top_features2]= True \nskimage.io.imshow(perturb_image(Xi2/2+0.5,mask2,superpixels2) )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask3= np.zeros(num_superpixels3) #The less relevant pixels are black and only the top superpixels are activated.\nmask3[top_features3]= True \nskimage.io.imshow(perturb_image(Xi3/2+0.5,mask3,superpixels3) )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask4= np.zeros(num_superpixels4) #The less relevant pixels are black and only the top superpixels are activated.\nmask4[top_features4]= True \nskimage.io.imshow(perturb_image(Xi4/2+0.5,mask4,superpixels4) )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask5= np.zeros(num_superpixels5) #The less relevant pixels are black and only the top superpixels are activated.\nmask5[top_features5]= True \nskimage.io.imshow(perturb_image(Xi5/2+0.5,mask5,superpixels5) )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask6= np.zeros(num_superpixels6) #The less relevant pixels are black and only the top superpixels are activated.\nmask6[top_features6]= True \nskimage.io.imshow(perturb_image(Xi6/2+0.5,mask6,superpixels6) )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_titles=[\"sj\",\"sj\",\"sj\",\"nsj\",\"nsj\",\"nsj\"]\nimagesXi=[Xi1,Xi2,Xi3,Xi4,Xi5,Xi6]\nmasks=[mask1,mask2,mask3,mask4,mask5,mask6]\nsuperpixels_list=[superpixels1,superpixels2,superpixels3,superpixels4,superpixels5,superpixels6]\n# Render\nfig, axs = plt.subplots(2, 3, figsize=(20, 20))\ni=0\nfor ax, title, Xi ,mask,superpixels in zip(axs.flatten(), image_titles, imagesXi,masks,superpixels_list):\n   \n    ax.set_title(title, fontsize=16)\n    ax.imshow(perturb_image(Xi/2+0.5,mask,superpixels) )\n    i=i+1\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Create the Lime explanation for the image\nexplanation = explainer.explain_instance(image, predict_fn, labels=(0,))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Get the top explanations\ntop_explanations = explanation.top_labels[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}